{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full Model Comparison: Graph Transformers vs Baselines\n",
        "\n",
        "This notebook implements a comprehensive comparison of:\n",
        "\n",
        "**Graph Transformers (Person A / Juliusz's work):**\n",
        "1. **GOAT** - Global attention with virtual nodes (O(N) complexity)\n",
        "2. **Exphormer** - Sparse attention using expander graphs (O(Nd) complexity)\n",
        "\n",
        "**Baseline GNN Models (Person B's contribution):**\n",
        "3. **GCN** - Graph Convolutional Network (O(E) complexity)\n",
        "4. **GAT** - Graph Attention Network (O(E) complexity)\n",
        "5. **GraphMLP** - Simple MLP baseline (no graph structure)\n",
        "\n",
        "---\n",
        "\n",
        "**From Project Description:**\n",
        "- Complexity vs. accuracy tradeoffs ‚úì\n",
        "- Compare against baselines ‚úì\n",
        "- Memory tracking (\"zrzucicie pamiƒôci\") ‚úì\n",
        "- Training time tracking ‚úì\n",
        "\n",
        "**Dataset:** ZINC (regression - predict molecular property)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "PyTorch version: 2.9.1\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "sys.path.append('..')  # Add project root to path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# All models - Graph Transformers + Baselines\n",
        "from models.goat import GOAT\n",
        "from models.exphormer import Exphormer\n",
        "from models.baselines import GCN, GAT, GraphMLP\n",
        "\n",
        "# Utilities\n",
        "from src.utils.positional_encodings import precompute_positional_encodings\n",
        "from src.utils.complexity import ComplexityTracker, count_parameters\n",
        "from src.utils.metrics import compute_metrics, MetricTracker\n",
        "\n",
        "# Data loading\n",
        "from src.utils.data import load_zinc_dataset, load_molhiv_dataset\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n",
        "\n",
        "Choose between CPU (quick test) or GPU (full experiments) mode.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ GPU MODE: Full experiment configuration\n",
            "\n",
            "Configuration:\n",
            "  Mode: GPU\n",
            "  Dataset size: Full\n",
            "  Batch size: 64\n",
            "  Epochs: 100\n",
            "  Hidden dim: 256\n",
            "  Num layers: 6\n",
            "  Num heads: 8\n",
            "  Learning rate: 0.0001\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION: Choose CPU (quick) or GPU (full)\n",
        "# ============================================================\n",
        "\n",
        "EXPERIMENT_MODE = \"cpu\"  # 'cpu' or 'gpu'\n",
        "\n",
        "if EXPERIMENT_MODE == 'cpu':\n",
        "    # CPU Configuration: Quick test (15-20 minutes)\n",
        "    USE_SMALL_SUBSET = True\n",
        "    SMALL_SIZE = 500\n",
        "    BATCH_SIZE = 16\n",
        "    NUM_EPOCHS = 15\n",
        "    HIDDEN_DIM = 64\n",
        "    NUM_LAYERS = 3\n",
        "    NUM_HEADS = 4\n",
        "    LEARNING_RATE = 1e-3\n",
        "    GRAD_CLIP_NORM = None\n",
        "    print(\"üñ•Ô∏è  CPU MODE: Quick test configuration\")\n",
        "else:\n",
        "    # GPU Configuration: Full experiments\n",
        "    USE_SMALL_SUBSET = False\n",
        "    SMALL_SIZE = None\n",
        "    BATCH_SIZE = 64\n",
        "    NUM_EPOCHS = 100  # Reduced for multi-model comparison\n",
        "    HIDDEN_DIM = 256\n",
        "    NUM_LAYERS = 6\n",
        "    NUM_HEADS = 8\n",
        "    LEARNING_RATE = 1e-4\n",
        "    GRAD_CLIP_NORM = 0.5\n",
        "    print(\"üöÄ GPU MODE: Full experiment configuration\")\n",
        "\n",
        "# Common settings\n",
        "PE_TYPE = 'laplacian'\n",
        "PE_DIM = 8\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Mode: {EXPERIMENT_MODE.upper()}\")\n",
        "print(f\"  Dataset size: {SMALL_SIZE if USE_SMALL_SUBSET else 'Full'}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
        "print(f\"  Num layers: {NUM_LAYERS}\")\n",
        "print(f\"  Num heads: {NUM_HEADS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ZINC dataset...\n",
            "Total graphs: 10,000\n",
            "Train: 8,000\n",
            "Val: 1,000\n",
            "Test: 1,000\n",
            "\n",
            "Precomputing laplacian positional encodings...\n",
            "Setting up laplacian positional encodings (dim=8)...\n",
            "Precomputing encodings...\n",
            "  Processed 100/10000 graphs\n",
            "  Processed 200/10000 graphs\n",
            "  Processed 300/10000 graphs\n",
            "  Processed 400/10000 graphs\n",
            "  Processed 500/10000 graphs\n",
            "  Processed 600/10000 graphs\n",
            "  Processed 700/10000 graphs\n",
            "  Processed 800/10000 graphs\n",
            "  Processed 900/10000 graphs\n",
            "  Processed 1000/10000 graphs\n",
            "  Processed 1100/10000 graphs\n",
            "  Processed 1200/10000 graphs\n",
            "  Processed 1300/10000 graphs\n",
            "  Processed 1400/10000 graphs\n",
            "  Processed 1500/10000 graphs\n",
            "  Processed 1600/10000 graphs\n",
            "  Processed 1700/10000 graphs\n",
            "  Processed 1800/10000 graphs\n",
            "  Processed 1900/10000 graphs\n",
            "  Processed 2000/10000 graphs\n",
            "  Processed 2100/10000 graphs\n",
            "  Processed 2200/10000 graphs\n",
            "  Processed 2300/10000 graphs\n",
            "  Processed 2400/10000 graphs\n",
            "  Processed 2500/10000 graphs\n",
            "  Processed 2600/10000 graphs\n",
            "  Processed 2700/10000 graphs\n",
            "  Processed 2800/10000 graphs\n",
            "  Processed 2900/10000 graphs\n",
            "  Processed 3000/10000 graphs\n",
            "  Processed 3100/10000 graphs\n",
            "  Processed 3200/10000 graphs\n",
            "  Processed 3300/10000 graphs\n",
            "  Processed 3400/10000 graphs\n",
            "  Processed 3500/10000 graphs\n",
            "  Processed 3600/10000 graphs\n",
            "  Processed 3700/10000 graphs\n",
            "  Processed 3800/10000 graphs\n",
            "  Processed 3900/10000 graphs\n",
            "  Processed 4000/10000 graphs\n",
            "  Processed 4100/10000 graphs\n",
            "  Processed 4200/10000 graphs\n",
            "  Processed 4300/10000 graphs\n",
            "  Processed 4400/10000 graphs\n",
            "  Processed 4500/10000 graphs\n",
            "  Processed 4600/10000 graphs\n",
            "  Processed 4700/10000 graphs\n",
            "  Processed 4800/10000 graphs\n",
            "  Processed 4900/10000 graphs\n",
            "  Processed 5000/10000 graphs\n",
            "  Processed 5100/10000 graphs\n",
            "  Processed 5200/10000 graphs\n",
            "  Processed 5300/10000 graphs\n",
            "  Processed 5400/10000 graphs\n",
            "  Processed 5500/10000 graphs\n",
            "  Processed 5600/10000 graphs\n",
            "  Processed 5700/10000 graphs\n",
            "  Processed 5800/10000 graphs\n",
            "  Processed 5900/10000 graphs\n",
            "  Processed 6000/10000 graphs\n",
            "  Processed 6100/10000 graphs\n",
            "  Processed 6200/10000 graphs\n",
            "  Processed 6300/10000 graphs\n",
            "  Processed 6400/10000 graphs\n",
            "  Processed 6500/10000 graphs\n",
            "  Processed 6600/10000 graphs\n",
            "  Processed 6700/10000 graphs\n",
            "  Processed 6800/10000 graphs\n",
            "  Processed 6900/10000 graphs\n",
            "  Processed 7000/10000 graphs\n",
            "  Processed 7100/10000 graphs\n",
            "  Processed 7200/10000 graphs\n",
            "  Processed 7300/10000 graphs\n",
            "  Processed 7400/10000 graphs\n",
            "  Processed 7500/10000 graphs\n",
            "  Processed 7600/10000 graphs\n",
            "  Processed 7700/10000 graphs\n",
            "  Processed 7800/10000 graphs\n",
            "  Processed 7900/10000 graphs\n",
            "  Processed 8000/10000 graphs\n",
            "  Processed 8100/10000 graphs\n",
            "  Processed 8200/10000 graphs\n",
            "  Processed 8300/10000 graphs\n",
            "  Processed 8400/10000 graphs\n",
            "  Processed 8500/10000 graphs\n",
            "  Processed 8600/10000 graphs\n",
            "  Processed 8700/10000 graphs\n",
            "  Processed 8800/10000 graphs\n",
            "  Processed 8900/10000 graphs\n",
            "  Processed 9000/10000 graphs\n",
            "  Processed 9100/10000 graphs\n",
            "  Processed 9200/10000 graphs\n",
            "  Processed 9300/10000 graphs\n",
            "  Processed 9400/10000 graphs\n",
            "  Processed 9500/10000 graphs\n",
            "  Processed 9600/10000 graphs\n",
            "  Processed 9700/10000 graphs\n",
            "  Processed 9800/10000 graphs\n",
            "  Processed 9900/10000 graphs\n",
            "  Processed 10000/10000 graphs\n",
            "Done!\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Load ZINC dataset\n",
        "print(\"Loading ZINC dataset...\")\n",
        "dataset, split_idx = load_zinc_dataset(root='../data')\n",
        "\n",
        "# Use subset for quick testing\n",
        "if USE_SMALL_SUBSET:\n",
        "    dataset = dataset[:SMALL_SIZE]\n",
        "    n = len(dataset)\n",
        "    split_idx = {\n",
        "        'train': torch.arange(int(0.8 * n)),\n",
        "        'valid': torch.arange(int(0.8 * n), int(0.9 * n)),\n",
        "        'test': torch.arange(int(0.9 * n), n)\n",
        "    }\n",
        "\n",
        "print(f\"Total graphs: {len(dataset):,}\")\n",
        "print(f\"Train: {len(split_idx['train']):,}\")\n",
        "print(f\"Val: {len(split_idx['valid']):,}\")\n",
        "print(f\"Test: {len(split_idx['test']):,}\")\n",
        "\n",
        "# Precompute positional encodings (for Graph Transformers)\n",
        "print(f\"\\nPrecomputing {PE_TYPE} positional encodings...\")\n",
        "dataset = precompute_positional_encodings(dataset, pe_type=PE_TYPE, pe_dim=PE_DIM)\n",
        "print(\"Done!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaders created!\n",
            "  Train batches: 125\n",
            "  Val batches: 16\n",
            "  Test batches: 16\n",
            "  Node feature dimension: 1\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    dataset[split_idx['train']],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset[split_idx['valid']],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset[split_idx['test']],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Get feature dimensions\n",
        "sample_data = dataset[0]\n",
        "ACTUAL_IN_CHANNELS = sample_data.x.shape[1]\n",
        "\n",
        "print(f\"Data loaders created!\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Val batches: {len(val_loader)}\")\n",
        "print(f\"  Test batches: {len(test_loader)}\")\n",
        "print(f\"  Node feature dimension: {ACTUAL_IN_CHANNELS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training and Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training functions defined!\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, device, grad_clip_norm=None):\n",
        "    \"\"\"Train for one epoch with complexity tracking\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    epoch_start = time.time()\n",
        "    \n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out.squeeze(), data.y.float())\n",
        "        loss.backward()\n",
        "        \n",
        "        if grad_clip_norm is not None:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip_norm)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        all_preds.append(out.detach().cpu())\n",
        "        all_labels.append(data.y.cpu())\n",
        "    \n",
        "    epoch_time = time.time() - epoch_start\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    \n",
        "    all_preds = torch.cat(all_preds, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "    train_mae = torch.abs(all_preds.squeeze() - all_labels).mean().item()\n",
        "    \n",
        "    return {'loss': avg_loss, 'mae': train_mae, 'time': epoch_time}\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        loss = criterion(out.squeeze(), data.y.float())\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        all_preds.append(out.cpu())\n",
        "        all_labels.append(data.y.cpu())\n",
        "    \n",
        "    avg_loss = total_loss / len(loader)\n",
        "    all_preds = torch.cat(all_preds, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "    mae = torch.abs(all_preds.squeeze() - all_labels).mean().item()\n",
        "    \n",
        "    return {'loss': avg_loss, 'mae': mae}\n",
        "\n",
        "\n",
        "def train_model(model, name, train_loader, val_loader, device, \n",
        "                num_epochs, learning_rate, grad_clip_norm=None, verbose=True):\n",
        "    \"\"\"Full training loop for a model\"\"\"\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    \n",
        "    history = {\n",
        "        'train_loss': [], 'train_mae': [],\n",
        "        'val_loss': [], 'val_mae': [],\n",
        "        'epoch_time': []\n",
        "    }\n",
        "    \n",
        "    best_val_mae = float('inf')\n",
        "    best_state = None\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"Training {name}\")\n",
        "        print(f\"{'='*80}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Train\n",
        "        train_metrics = train_epoch(model, train_loader, optimizer, criterion, device, grad_clip_norm)\n",
        "        \n",
        "        # Validate\n",
        "        val_metrics = evaluate(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Track metrics\n",
        "        history['train_loss'].append(train_metrics['loss'])\n",
        "        history['train_mae'].append(train_metrics['mae'])\n",
        "        history['val_loss'].append(val_metrics['loss'])\n",
        "        history['val_mae'].append(val_metrics['mae'])\n",
        "        history['epoch_time'].append(train_metrics['time'])\n",
        "        \n",
        "        # Save best model\n",
        "        if val_metrics['mae'] < best_val_mae:\n",
        "            best_val_mae = val_metrics['mae']\n",
        "            best_state = model.state_dict().copy()\n",
        "        \n",
        "        # Print progress\n",
        "        if verbose and (epoch % 10 == 0 or epoch == num_epochs - 1):\n",
        "            print(f\"Epoch {epoch:3d} | \"\n",
        "                  f\"Train MAE: {train_metrics['mae']:.4f} | \"\n",
        "                  f\"Val MAE: {val_metrics['mae']:.4f} | \"\n",
        "                  f\"Time: {train_metrics['time']:.2f}s\")\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"\\n{name} Training Complete!\")\n",
        "        print(f\"  Best Val MAE: {best_val_mae:.4f}\")\n",
        "        print(f\"  Total Time: {total_time:.1f}s\")\n",
        "    \n",
        "    return history, best_val_mae, best_state, total_time\n",
        "\n",
        "print(\"Training functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create All Models\n",
        "\n",
        "We create all 5 models with comparable capacity for fair comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL SUMMARY\n",
            "================================================================================\n",
            "Model           |      Parameters |           Complexity\n",
            "------------------------------------------------------------\n",
            "GOAT            |       5,994,497 | O(N) - virtual nodes\n",
            "Exphormer       |       6,389,255 | O(Nd) - expander sparse\n",
            "GCN             |         398,593 | O(E) - local message passing\n",
            "GAT             |         401,665 | O(E) - attention on edges\n",
            "GraphMLP        |         329,729 | O(N) - no graph structure\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store all models and their results\n",
        "models = {}\n",
        "results = {}\n",
        "\n",
        "# ============================================================\n",
        "# 1. GOAT - Global Transformer (Juliusz's implementation)\n",
        "# ============================================================\n",
        "models['GOAT'] = GOAT(\n",
        "    in_channels=ACTUAL_IN_CHANNELS,\n",
        "    hidden_channels=HIDDEN_DIM,\n",
        "    out_channels=1,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    num_virtual_nodes=1,\n",
        "    pe_dim=PE_DIM,\n",
        "    dropout=0.1,\n",
        "    task_type='graph_classification',\n",
        ").to(device)\n",
        "\n",
        "# ============================================================\n",
        "# 2. Exphormer - Sparse Transformer (Juliusz's implementation)\n",
        "# ============================================================\n",
        "models['Exphormer'] = Exphormer(\n",
        "    in_channels=ACTUAL_IN_CHANNELS,\n",
        "    hidden_channels=HIDDEN_DIM,\n",
        "    out_channels=1,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    expander_degree=4,\n",
        "    expander_method='random',\n",
        "    pe_dim=PE_DIM,\n",
        "    dropout=0.1,\n",
        "    task_type='graph_classification',\n",
        ").to(device)\n",
        "\n",
        "# ============================================================\n",
        "# 3. GCN - Baseline (Person B)\n",
        "# ============================================================\n",
        "models['GCN'] = GCN(\n",
        "    in_channels=ACTUAL_IN_CHANNELS,\n",
        "    hidden_channels=HIDDEN_DIM,\n",
        "    out_channels=1,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=0.1,\n",
        "    task_type='graph_classification',\n",
        ").to(device)\n",
        "\n",
        "# ============================================================\n",
        "# 4. GAT - Baseline (Person B)\n",
        "# ============================================================\n",
        "models['GAT'] = GAT(\n",
        "    in_channels=ACTUAL_IN_CHANNELS,\n",
        "    hidden_channels=HIDDEN_DIM,\n",
        "    out_channels=1,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=0.1,\n",
        "    task_type='graph_classification',\n",
        ").to(device)\n",
        "\n",
        "# ============================================================\n",
        "# 5. GraphMLP - Baseline (no graph structure)\n",
        "# ============================================================\n",
        "models['GraphMLP'] = GraphMLP(\n",
        "    in_channels=ACTUAL_IN_CHANNELS,\n",
        "    hidden_channels=HIDDEN_DIM,\n",
        "    out_channels=1,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=0.1,\n",
        "    task_type='graph_classification',\n",
        ").to(device)\n",
        "\n",
        "# Print model summaries\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Model':<15} | {'Parameters':>15} | {'Complexity':>20}\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "complexity_info = {\n",
        "    'GOAT': 'O(N) - virtual nodes',\n",
        "    'Exphormer': 'O(Nd) - expander sparse',\n",
        "    'GCN': 'O(E) - local message passing',\n",
        "    'GAT': 'O(E) - attention on edges',\n",
        "    'GraphMLP': 'O(N) - no graph structure',\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    params = count_parameters(model)\n",
        "    results[name] = {'params': params['total']}\n",
        "    print(f\"{name:<15} | {params['total']:>15,} | {complexity_info[name]:>20}\")\n",
        "\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING ALL MODELS\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Training GOAT\n",
            "================================================================================\n",
            "Epoch   0 | Train MAE: 1.1925 | Val MAE: 1.1275 | Time: 37.15s\n",
            "Epoch  10 | Train MAE: 0.7933 | Val MAE: 0.9294 | Time: 38.26s\n",
            "Epoch  20 | Train MAE: 0.7260 | Val MAE: 0.7316 | Time: 37.66s\n",
            "Epoch  30 | Train MAE: 0.6800 | Val MAE: 0.6828 | Time: 37.72s\n",
            "Epoch  40 | Train MAE: 0.6327 | Val MAE: 0.6448 | Time: 38.13s\n"
          ]
        }
      ],
      "source": [
        "# Store training histories\n",
        "histories = {}\n",
        "\n",
        "# Track GPU memory before training\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING ALL MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Reset memory tracking\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "    \n",
        "    # Train model\n",
        "    history, best_mae, best_state, total_time = train_model(\n",
        "        model=model,\n",
        "        name=name,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        device=device,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        grad_clip_norm=GRAD_CLIP_NORM,\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    # Store results\n",
        "    histories[name] = history\n",
        "    results[name]['best_val_mae'] = best_mae\n",
        "    results[name]['total_time'] = total_time\n",
        "    results[name]['avg_epoch_time'] = np.mean(history['epoch_time'])\n",
        "    \n",
        "    # Track peak memory\n",
        "    if torch.cuda.is_available():\n",
        "        results[name]['peak_memory_mb'] = torch.cuda.max_memory_allocated() / 1e6\n",
        "    else:\n",
        "        results[name]['peak_memory_mb'] = 0\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ALL MODELS TRAINED!\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive results table\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"COMPREHENSIVE BENCHMARK RESULTS\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "print(f\"\\n{'Model':<15} | {'Best Val MAE':>12} | {'Params':>12} | {'Avg Epoch (s)':>14} | {'Peak Mem (MB)':>14} | {'Total Time (s)':>15}\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Sort by best val MAE\n",
        "sorted_models = sorted(results.items(), key=lambda x: x[1]['best_val_mae'])\n",
        "\n",
        "for name, res in sorted_models:\n",
        "    print(f\"{name:<15} | {res['best_val_mae']:>12.4f} | {res['params']:>12,} | \"\n",
        "          f\"{res['avg_epoch_time']:>14.2f} | {res['peak_memory_mb']:>14.1f} | {res['total_time']:>15.1f}\")\n",
        "\n",
        "print(\"-\"*100)\n",
        "\n",
        "# Find winners in each category\n",
        "best_accuracy = min(results.items(), key=lambda x: x[1]['best_val_mae'])\n",
        "most_efficient = min(results.items(), key=lambda x: x[1]['params'])\n",
        "fastest = min(results.items(), key=lambda x: x[1]['avg_epoch_time'])\n",
        "lowest_memory = min(results.items(), key=lambda x: x[1]['peak_memory_mb'])\n",
        "\n",
        "print(f\"\\nüèÜ Best Accuracy: {best_accuracy[0]} (MAE: {best_accuracy[1]['best_val_mae']:.4f})\")\n",
        "print(f\"‚ö° Fastest: {fastest[0]} ({fastest[1]['avg_epoch_time']:.2f}s/epoch)\")\n",
        "print(f\"üíæ Lowest Memory: {lowest_memory[0]} ({lowest_memory[1]['peak_memory_mb']:.1f} MB)\")\n",
        "print(f\"üì¶ Most Efficient: {most_efficient[0]} ({most_efficient[1]['params']:,} params)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Color palette\n",
        "colors = {\n",
        "    'GOAT': '#2ecc71',       # Green\n",
        "    'Exphormer': '#3498db',  # Blue\n",
        "    'GCN': '#e74c3c',        # Red\n",
        "    'GAT': '#9b59b6',        # Purple\n",
        "    'GraphMLP': '#95a5a6',   # Gray\n",
        "}\n",
        "\n",
        "epochs = range(NUM_EPOCHS)\n",
        "\n",
        "# Plot 1: Training Loss Curves\n",
        "ax = axes[0, 0]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(epochs, history['train_loss'], label=name, color=colors[name], alpha=0.8, linewidth=2)\n",
        "ax.set_xlabel('Epoch', fontsize=12)\n",
        "ax.set_ylabel('Training Loss', fontsize=12)\n",
        "ax.set_title('Training Loss Curves', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Validation MAE Curves\n",
        "ax = axes[0, 1]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(epochs, history['val_mae'], label=name, color=colors[name], alpha=0.8, linewidth=2)\n",
        "ax.set_xlabel('Epoch', fontsize=12)\n",
        "ax.set_ylabel('Validation MAE', fontsize=12)\n",
        "ax.set_title('Validation MAE (Lower is Better)', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Epoch Time Comparison\n",
        "ax = axes[0, 2]\n",
        "for name, history in histories.items():\n",
        "    ax.plot(epochs, history['epoch_time'], label=name, color=colors[name], alpha=0.8, linewidth=2)\n",
        "ax.set_xlabel('Epoch', fontsize=12)\n",
        "ax.set_ylabel('Time (seconds)', fontsize=12)\n",
        "ax.set_title('Training Time per Epoch', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Best MAE Bar Chart\n",
        "ax = axes[1, 0]\n",
        "model_names = list(results.keys())\n",
        "maes = [results[name]['best_val_mae'] for name in model_names]\n",
        "bars = ax.bar(model_names, maes, color=[colors[name] for name in model_names], alpha=0.8)\n",
        "ax.set_ylabel('Best Validation MAE', fontsize=12)\n",
        "ax.set_title('Best Validation MAE Comparison', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, mae in zip(bars, maes):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "            f'{mae:.4f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Plot 5: Complexity vs Accuracy Trade-off\n",
        "ax = axes[1, 1]\n",
        "for name in model_names:\n",
        "    ax.scatter([results[name]['params']], [results[name]['best_val_mae']],\n",
        "               s=300, label=name, color=colors[name], alpha=0.8, edgecolors='black', linewidth=2)\n",
        "    ax.annotate(name, (results[name]['params'], results[name]['best_val_mae']),\n",
        "                textcoords=\"offset points\", xytext=(10, 5), fontsize=10)\n",
        "ax.set_xlabel('Number of Parameters', fontsize=12)\n",
        "ax.set_ylabel('Best Validation MAE', fontsize=12)\n",
        "ax.set_title('Complexity vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: Speed vs Accuracy Trade-off\n",
        "ax = axes[1, 2]\n",
        "for name in model_names:\n",
        "    ax.scatter([results[name]['avg_epoch_time']], [results[name]['best_val_mae']],\n",
        "               s=300, label=name, color=colors[name], alpha=0.8, edgecolors='black', linewidth=2)\n",
        "    ax.annotate(name, (results[name]['avg_epoch_time'], results[name]['best_val_mae']),\n",
        "                textcoords=\"offset points\", xytext=(10, 5), fontsize=10)\n",
        "ax.set_xlabel('Average Epoch Time (seconds)', fontsize=12)\n",
        "ax.set_ylabel('Best Validation MAE', fontsize=12)\n",
        "ax.set_title('Speed vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('full_model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPlots saved to full_model_comparison.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY AND CONCLUSIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä EXPERIMENT DETAILS:\")\n",
        "print(f\"   Dataset: ZINC (regression)\")\n",
        "print(f\"   Training samples: {len(split_idx['train']):,}\")\n",
        "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"   Device: {device}\")\n",
        "\n",
        "print(\"\\nüìà MODEL RANKINGS (by Validation MAE):\")\n",
        "for i, (name, res) in enumerate(sorted_models, 1):\n",
        "    print(f\"   {i}. {name}: {res['best_val_mae']:.4f}\")\n",
        "\n",
        "print(\"\\n‚è±Ô∏è TRAINING SPEED (avg seconds per epoch):\")\n",
        "speed_sorted = sorted(results.items(), key=lambda x: x[1]['avg_epoch_time'])\n",
        "for name, res in speed_sorted:\n",
        "    print(f\"   {name}: {res['avg_epoch_time']:.2f}s\")\n",
        "\n",
        "print(\"\\nüíæ MEMORY USAGE (peak MB):\")\n",
        "mem_sorted = sorted(results.items(), key=lambda x: x[1]['peak_memory_mb'])\n",
        "for name, res in mem_sorted:\n",
        "    print(f\"   {name}: {res['peak_memory_mb']:.1f} MB\")\n",
        "\n",
        "print(\"\\nüéØ KEY FINDINGS:\")\n",
        "\n",
        "# Compare transformers vs baselines\n",
        "transformer_maes = [results['GOAT']['best_val_mae'], results['Exphormer']['best_val_mae']]\n",
        "baseline_maes = [results['GCN']['best_val_mae'], results['GAT']['best_val_mae']]\n",
        "best_transformer = 'GOAT' if results['GOAT']['best_val_mae'] < results['Exphormer']['best_val_mae'] else 'Exphormer'\n",
        "best_baseline = 'GCN' if results['GCN']['best_val_mae'] < results['GAT']['best_val_mae'] else 'GAT'\n",
        "\n",
        "print(f\"   ‚Ä¢ Best Transformer: {best_transformer} (MAE: {results[best_transformer]['best_val_mae']:.4f})\")\n",
        "print(f\"   ‚Ä¢ Best Baseline: {best_baseline} (MAE: {results[best_baseline]['best_val_mae']:.4f})\")\n",
        "\n",
        "improvement = (results[best_baseline]['best_val_mae'] - results[best_transformer]['best_val_mae']) / results[best_baseline]['best_val_mae'] * 100\n",
        "if improvement > 0:\n",
        "    print(f\"   ‚Ä¢ Graph Transformers improve by {improvement:.1f}% over best baseline\")\n",
        "else:\n",
        "    print(f\"   ‚Ä¢ Baseline models competitive with Graph Transformers\")\n",
        "\n",
        "# GraphMLP comparison\n",
        "mlp_mae = results['GraphMLP']['best_val_mae']\n",
        "best_graph_mae = min([results[name]['best_val_mae'] for name in ['GOAT', 'Exphormer', 'GCN', 'GAT']])\n",
        "graph_improvement = (mlp_mae - best_graph_mae) / mlp_mae * 100\n",
        "print(f\"   ‚Ä¢ Graph structure helps: {graph_improvement:.1f}% improvement over MLP\")\n",
        "\n",
        "print(\"\\nüìù COMPLEXITY vs ACCURACY TRADE-OFF (Teacher's Requirement):\")\n",
        "print(f\"   ‚Ä¢ GOAT: O(N) complexity with {results['GOAT']['best_val_mae']:.4f} MAE\")\n",
        "print(f\"   ‚Ä¢ Exphormer: O(Nd) complexity with {results['Exphormer']['best_val_mae']:.4f} MAE\")\n",
        "print(f\"   ‚Ä¢ GCN: O(E) complexity with {results['GCN']['best_val_mae']:.4f} MAE\")\n",
        "print(f\"   ‚Ä¢ GAT: O(E) complexity with {results['GAT']['best_val_mae']:.4f} MAE\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Benchmark complete! Results ready for report.\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Export Results for Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Save results to JSON for later analysis\n",
        "export_results = {\n",
        "    'experiment_config': {\n",
        "        'mode': EXPERIMENT_MODE,\n",
        "        'num_epochs': NUM_EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'hidden_dim': HIDDEN_DIM,\n",
        "        'num_layers': NUM_LAYERS,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'device': str(device),\n",
        "        'dataset': 'ZINC',\n",
        "        'train_size': int(len(split_idx['train'])),\n",
        "    },\n",
        "    'results': {\n",
        "        name: {\n",
        "            'best_val_mae': res['best_val_mae'],\n",
        "            'params': res['params'],\n",
        "            'avg_epoch_time': res['avg_epoch_time'],\n",
        "            'peak_memory_mb': res['peak_memory_mb'],\n",
        "            'total_time': res['total_time'],\n",
        "        }\n",
        "        for name, res in results.items()\n",
        "    },\n",
        "    'histories': {\n",
        "        name: {\n",
        "            'train_loss': hist['train_loss'],\n",
        "            'train_mae': hist['train_mae'],\n",
        "            'val_loss': hist['val_loss'],\n",
        "            'val_mae': hist['val_mae'],\n",
        "            'epoch_time': hist['epoch_time'],\n",
        "        }\n",
        "        for name, hist in histories.items()\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('benchmark_results.json', 'w') as f:\n",
        "    json.dump(export_results, f, indent=2)\n",
        "\n",
        "print(\"Results exported to benchmark_results.json\")\n",
        "print(\"\\nYou can use this file to regenerate plots or include data in your report.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
